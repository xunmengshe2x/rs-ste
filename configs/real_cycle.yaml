model:
  base_learning_rate: 4.5e-06
  target: model.model.RSSTE
  params:
    transformer_config:
      target: model.minGPT.GPT
      params:
        vocab_size: 96 
        block_size: 577 # (((8x32=256)+32) = 288) x 2 + 1 = 577
        n_layer: 12
        n_head: 6
        n_embd: 384
    n_embd: 384
    alphabet:  data/alphabet/en.txt
    max_text_len: 32
    training_mode: "real_cycle"
  
data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 4
    num_workers: 8
    train:
      target: data.dataset.TrainDataset
      params:
        training_annotation_file: 
          - data/annotation/real_train.pkl
        training_data_proportion:
          - 1
        size: 32
    validation:
      target: data.dataset.InferenceDataset
      params:
        test_annotation_file: data/annotation/real_test_annotations.pkl
        size: 32